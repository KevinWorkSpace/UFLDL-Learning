# 使用卷积进行特征提取（Feature Extraction Using Convolution）  
##  
## 概览（Overview）  

在之前的练习中的图片分辨率都偏低，如手写数字图像。在本节中将会学到一种方法，能够用在实际中更大的图像数据集上。  

## 全连接网络（Fully Connected Networks）  

在稀疏编码器（译者注：后文会讲到，这部分是老版的教程，所以内容跳跃了）中，一种设计选择是先前已经讲到的“全连接”，即所有的隐含层单元与所有输入单元完全连接起来。在先前练习中使用的是相对较小的图像（例如，在稀疏编码的任务中 $8 \times 8$ 像素大小的图像，以及 MNIST 数据集中 $28 \times 28$ 像素大小的图像），这种“全连接”方式的特征学习，虽然在整个图像上的计算是可行的。然而，对于更大图像，如 $96 \times 96$ 像素大小的图像的学习来说，由于连接是全连接的形式来做特征学习，计算代价是很大的——网络大概会有 $10^4$ 数量级的输入单元，假设要学习 $100$ 个特征（译者注：即下一层有 $100$ 隐含层单元，该过程是在学习一种基于原始数据的压缩特征表达），那就会有 $10^6$ 数量级（译者注：输入层 $10^4$ 个输入单元与第一个隐含层的 $100$ 个隐含单元全连接需要 $10^6$ 个参数）的参数需要学习。相较于 $28 \times 28$ 像素大小的图像（译者注：假设隐含层也是 $100$ 个神经元，仅输入层到第一个隐含层需要的参数就有 $28 \times 28 \times 100 = 78400$ 个，即需要的参数的量级为 $10^4$ ），在前向和反向传播的计算上大图像比小图像也会慢大约 $10^2$ 倍（译者注：单纯从二者相差的参数量级上的比较）。  

## 局部连接网络（Locally Connected Networks）  

该问题的一种简单解决方案是限制隐含单元与输入单元的连接数目，也就是说，隐含单元只允许连接一部分的输入单元（译者注：即隐藏层的神经元与原图中的一个小图建立连接权重）。具体而言，每个隐藏单元将连接到输入像素中的一个小的连续区域。（对于不同于图像的数据形式，也有一种自然的方式来选择从输入单元到一个隐含单元需要处理的“连续组”，例如，对于音频，一个隐藏单元可能被连接到一个与之特定时间跨度对应的音频剪辑的输入单元上。）  

局部连接网络的这一想法也借鉴了在生物学上早期视觉系统的观点。具体而言，视觉皮层的神经元有着局部感受区域（即，它们只会对某一位置的刺激做出反应）。  

## 卷积（Convolutions）  

自然世界中的图像有着“固定不变”的属性（译者注：或称为“静态性”），这也意味这图像的某一部分的数据和另一部分的数据是一样的。这表明，在一张图像上某部分的特征也可应用到该图片的其它部分，基于这一观点——网络可以使用不同的特征，应用到局部数据一样但不同的位置上。  

更确切地说，从一张高分辨率图像上随机地抽样小图片（比方说 $8 \times 8$ 大小的图片）做特征学习，将这个完成学习的 $8 \times 8$ 大小的特征检测器（译者注：学习 $8 \times 8$ 特征滤波器的权重）应用到这幅图片的其它任何地方。可以把学到的 $8 \times 8$ 特征（译者注：滤波器），通过将它们与更大图片“卷”起来的方式，在同一张图片上获得在每个位置处不同的特征激活值。  

讲个具体的例子，假设您已经从 $96 \times 96$ 大小的图片上做了 $8 \times 8$ 大小的抽样的特征学习。再进一步假设，这一特征学习过程是通过有着 $100$ 个隐含单元的自动编码器完成的。为了获得卷积特征（即 $96 \times 96$ 大小的图片上每 $8 \times 8$ 大小范围的特征，这个 $8 \times 8$ 区域是从 $(1,1), (2,2), ...(89,89)$ ），您将会从原图提取 $8 \times 8$ 大小的小图片，通过您训练的稀疏自动编码器来获取特征激活。这将会产生 $100$ 组（译者注：对应这一卷积层的 $100$ 个神经元或者称为滤波器）的 $89 \times 89$ 大小的卷积特征。  

<center><img src="./images/Convolution_schematic.gif" /></center>  

正式地说，给定分辨率大小为 $r \times c$ 的图像 $x_{large}$ ，首先对这些图像进行抽样，抽样出大小为 $a\times b$ 的小图像 $x_{small}$ ，利用这些小图像通过稀疏自动编码器来进行 $k$ 个特征的学习（译者注：这里特征的学习，即滤波器或神经元权重的学习。 $k$ 是卷积层神经元或滤波器的数目，也是该卷积层输出的通道数），这个学习过程是通过给出的从可见单元（译者注：原文中是$visible\ units$，推测是输入单元，一般来说可见单元既包括输入单元也包括输出单元）到隐含单元的权重 $W^{(1)}$ 和偏置 $b^{(1)}$，计算 $f = \sigma(W^{(1)}x_{small} + b^{(1)})$ （其中， $\sigma$ 是 S 型函数）。对从大图像抽样出的每个大小为 $a\times b$ 的小图像 $x_{s}$ ，计算该小图像的 $f_s = \sigma(W^{(1)}x_s + b^{(1)})$ （译者注：其中， $l=1,...,k$ ），将这一张大图上的小图计算完，得出这张大图像的 $f_{convolved}$，这个卷积特征是一个规模为 $k \times (r - a + 1) \times (c - b + 1)$ 的三维张量。  

下一节中，将进一步介绍如何将这些特征“池化”到一起，以获得用于分类的更好特征。
